{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# ðŸ““ Catalist â†’ MAP Schema Migration Notebook (Bundle Format)\n",
    "\n",
    "This notebook converts the **MAP Types Airtable export (CSV)** into a set of **flat JSON descriptor files** plus a **manifest** (`schema.json`), matching our new loader design.\n",
    "\n",
    "**Overall Workflow**\n",
    "1. Imports & configuration\n",
    "2. Load CSV and normalize\n",
    "3. Helper functions: `$ref` and headers\n",
    "4. Row â†’ descriptor conversion (Holon, Property, Value, Enum, Relationship)\n",
    "5. Group descriptors by `type_kind` and write flat files\n",
    "6. Build and write `schema.json` manifest\n",
    "7. (Optional) JSON-Schema validation\n",
    "---\n",
    "# 1. Imports & Config\n"
   ],
   "id": "f3bd3985f96a7060"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T20:07:31.107694Z",
     "start_time": "2025-07-01T20:07:31.081948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import json, itertools\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths (edit as needed)\n",
    "CSV_PATH   = Path(\"data/MAP Types-Grid view.csv\")        # private CSV\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "OUT_DIR    = Path(f\"output/map_types_{timestamp}\")        # bundle output dir\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Which TypeKinds to export\n",
    "TYPEKINDS = [\n",
    "    \"HolonType\", \"PropertyType\", \"ValueType\",\n",
    "    \"EnumType\", \"EnumVariantType\", \"RelationshipType\"\n",
    "]\n",
    "\n",
    "# Bundle manifest info\n",
    "default_schema = {\n",
    "    \"type_name\":   \"CatalistSchema\",\n",
    "    \"label\":       \"Catalist 2.5 Schema\",\n",
    "    \"description\": \"Types generated from Catalist Airtable export\"\n",
    "}"
   ],
   "id": "3ebfbd3547a5d961",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# 2. Load CSV + Normalize"
   ],
   "id": "af6f1395643d06df"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-01T20:07:31.203047Z",
     "start_time": "2025-07-01T20:07:31.162679Z"
    }
   },
   "source": [
    "# Read and preview\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(f\"Loaded {len(df)} rows Ã— {len(df.columns)} cols\")\n",
    "df.head(3)\n",
    "\n",
    "# Normalizer for Airtable checkboxes\n",
    "\n",
    "def bool_norm(val):\n",
    "    return bool(val) if isinstance(val, bool) else str(val).strip().lower() == \"checked\""
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 181 rows Ã— 45 cols\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# 3. Helpers: `$ref` & Common Header"
   ],
   "id": "111e71cf2caa852a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T20:07:31.222541Z",
     "start_time": "2025-07-01T20:07:31.219358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Build a JSON-$ref object (with optional schema/space)\n",
    "def ref(type_name: str, schema: str = None, space: str = None):\n",
    "    obj = {\"type_name\": type_name}\n",
    "    if schema: obj[\"schema\"] = schema\n",
    "    if space:  obj[\"space\"]  = space\n",
    "    return {\"$ref\": obj}\n",
    "\n",
    "# Common header fields for all descriptors\n",
    "def common_header(row, descriptor_name):\n",
    "    \"\"\"\n",
    "    Return the fields common to every descriptor type.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"descriptor_name\": descriptor_name,\n",
    "        \"label\":           row.get(\"Label (Human Readable)\", \"\") or \"\",\n",
    "        \"description\":     row.get(\"Description\", \"\") or \"\",\n",
    "        \"is_dependent\":    bool_norm(row.get(\"Is Dependent\", False)),\n",
    "        \"is_value_type\":   bool_norm(row.get(\"Is ValueType\", False)),\n",
    "        \"described_by\":    ref(row[\"TypeKind\"]),\n",
    "        \"is_subtype_of\":   None  # TODO: populate when CSV supports\n",
    "    }"
   ],
   "id": "6cae51de74478f9b",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# 4. Row â†’ Descriptor Conversion"
   ],
   "id": "f86f68615978391c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T20:07:31.238637Z",
     "start_time": "2025-07-01T20:07:31.231295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def common_header(row, descriptor_name):\n",
    "    \"\"\"Return the pieces common to every TypeKind.\"\"\"\n",
    "    return {\n",
    "        \"descriptor_name\" : descriptor_name,\n",
    "        \"label\"           : row.get(\"Label (Human Readable)\", \"\") or \"\",\n",
    "        \"description\"     : row.get(\"Description\", \"\") or \"\",\n",
    "        \"is_dependent\"    : bool_norm(row.get(\"Is Dependent\", False)),\n",
    "        \"is_value_type\"   : bool_norm(row.get(\"Is ValueType\", False)),\n",
    "        \"described_by\"    : ref(row[\"TypeKind\"]),      # all core meta-types are addressable\n",
    "        \"is_subtype_of\"   : None                       # TODO: populate when CSV adds this\n",
    "    }\n",
    "\n",
    "# HolonType\n",
    "\n",
    "def row_to_holontype(row):\n",
    "    name = row[\"Type Name\"]\n",
    "    spec = common_header(row, f\"{name}Descriptor\")\n",
    "    # properties & key_properties\n",
    "    raw = row.get(\"MAP PROPERTIES PropertyTypes\", \"\")\n",
    "    spec[\"properties\"]     = [] if pd.isna(raw) else [p.strip() for p in str(raw).split(\",\") if p.strip()]\n",
    "    raw = row.get(\"MAP KEY_PROPERTIES PropertyTypes\", \"\")\n",
    "    spec[\"key_properties\"]  = [] if pd.isna(raw) else [k.strip() for k in str(raw).split(\",\") if k.strip()]\n",
    "    spec[\"type_name\"]       = name\n",
    "    return {\"type_kind\": \"HolonType\", \"type_name\": name,\n",
    "            \"described_by\": ref(\"HolonType\"), \"spec\": spec}\n",
    "\n",
    "# PropertyType\n",
    "\n",
    "def row_to_propertytype(row):\n",
    "    name = row[\"Type Name\"]\n",
    "    spec = common_header(row, f\"{name}_descriptor\")\n",
    "    spec[\"property_name\"] = name\n",
    "    ref_val = row.get(\"ValueType (VALUE_TYPE_FOR)\", \"\").strip()\n",
    "    spec[\"value_type\"]    = ref(ref_val) if ref_val else None\n",
    "    return {\"type_kind\": \"PropertyType\", \"type_name\": name,\n",
    "            \"described_by\": ref(\"PropertyType\"), \"spec\": spec}\n",
    "\n",
    "# ValueType, EnumType, EnumVariantType similarâ€¦\n",
    "# RelationshipType (flattened, with collection fields.)\n",
    "\n",
    "def row_to_relationshiptype(row):\n",
    "    rel = row[\"Type Name\"]\n",
    "    # normalize fields\n",
    "    source_owns  = bool_norm(row.get(\"Source Owns Relationship\", False))\n",
    "    deletion_sem = row.get(\"Deletion Semantic\")\n",
    "    deletion_sem = None if pd.isna(deletion_sem) or not str(deletion_sem).strip() else deletion_sem\n",
    "    load_links   = bool_norm(row.get(\"Load Links Immediate\", False))\n",
    "    load_holons  = bool_norm(row.get(\"Load Holons Immediate\", False))\n",
    "    has_inv      = row.get(\"Has Inverse\") or None\n",
    "    # cardinality\n",
    "    tmin = int(row.get(\"Target Min Cardinality\") or 0)\n",
    "    tmax = int(row.get(\"Target Max Cardinality\") or 1)\n",
    "    tsem = row.get(\"Target Semantic\", \"Set\")\n",
    "    # iterate sources Ã— targets\n",
    "    outs = []\n",
    "    froms = [f.strip() for f in str(row.get(\"Relationship From\", \"\")).split(\",\") if f.strip()]\n",
    "    tos   = [t.strip() for t in str(row.get(\"Relationship To\", \"\")).split(\",\") if t.strip()]\n",
    "    for src, tgt in itertools.product(froms, tos):\n",
    "        tname = f\"{src}-{rel}->{tgt}\"\n",
    "        spec = common_header(row, f\"{tname}Descriptor\")\n",
    "        spec.update({\n",
    "            \"relationship_name\":        rel,\n",
    "            \"source_owns_relationship\": source_owns,\n",
    "            \"deletion_semantic\":        deletion_sem,\n",
    "            \"load_links_immediate\":     load_links,\n",
    "            \"load_holons_immediate\":    load_holons,\n",
    "            \"has_inverse\":              ref(has_inv) if has_inv else None,\n",
    "            \"target_holon_type\":        ref(tgt, schema=default_schema[\"type_name\"]),\n",
    "            \"target_semantic\":          tsem,\n",
    "            \"target_min_cardinality\":   tmin,\n",
    "            \"target_max_cardinality\":   tmax\n",
    "        })\n",
    "        outs.append({\n",
    "            \"type_kind\":    \"RelationshipType\",\n",
    "            \"type_name\":    tname,\n",
    "            \"described_by\": ref(\"RelationshipType\"),\n",
    "            \"spec\":         spec\n",
    "        })\n",
    "    return outs\n"
   ],
   "id": "30f3e802e1d51365",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# 5. Group and Write Flat JSON Files"
   ],
   "id": "e7b2049d7bf08062"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T20:07:31.280896Z",
     "start_time": "2025-07-01T20:07:31.247380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert all rowsâ†’descriptors\n",
    "all_desc = []\n",
    "for _, row in df.iterrows():\n",
    "    kind = row[\"TypeKind\"]\n",
    "    if kind not in TYPEKINDS: continue\n",
    "    if kind == \"HolonType\":      all_desc.append(row_to_holontype(row))\n",
    "    elif kind == \"PropertyType\": all_desc.append(row_to_propertytype(row))\n",
    "    elif kind == \"RelationshipType\": all_desc.extend(row_to_relationshiptype(row))\n",
    "    # TODO: ValueType, EnumType, EnumVariantType\n",
    "\n",
    "# Bucket by type_kind\n",
    "descriptor_buckets = {}\n",
    "for d in all_desc:\n",
    "    descriptor_buckets.setdefault(d[\"type_kind\"], []).append(d)\n",
    "\n",
    "# Write each bucket to its own JSON\n",
    "for kind, items in descriptor_buckets.items():\n",
    "    fname = OUT_DIR / f\"{kind.lower()}s.json\"\n",
    "    with open(fname, 'w') as f:\n",
    "        json.dump(items, f, indent=2)\n",
    "    print(f\"Wrote {len(items)} descriptors â†’ {fname}\")"
   ],
   "id": "bf0f3dfffe35b1a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 81 descriptors â†’ output/map_types_20250701_130731/holontypes.json\n",
      "Wrote 136 descriptors â†’ output/map_types_20250701_130731/relationshiptypes.json\n",
      "Wrote 31 descriptors â†’ output/map_types_20250701_130731/propertytypes.json\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# 6. Manifest: Build and Write `schema.json`"
   ],
   "id": "83bac8dc2c89380"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T20:07:31.325267Z",
     "start_time": "2025-07-01T20:07:31.312776Z"
    }
   },
   "cell_type": "code",
   "source": [
    "manifest = {\n",
    "    \"schema\": {\n",
    "        \"type_name\":   default_schema[\"type_name\"],\n",
    "        \"described_by\": ref(\"SchemaType\", schema=\"CoreSchema\"),\n",
    "        \"properties\": {\n",
    "            \"name\":        default_schema[\"label\"],\n",
    "            \"description\": default_schema[\"description\"]\n",
    "        }\n",
    "    },\n",
    "    \"type_files\": [f.name for f in OUT_DIR.glob(\"*.json\") if f.name != \"schema.json\"]\n",
    "}\n",
    "with open(OUT_DIR / \"schema.json\", 'w') as f:\n",
    "    json.dump(manifest, f, indent=2)\n",
    "print(\"Wrote manifest â†’ schema.json\")"
   ],
   "id": "28abac0709f432d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote manifest â†’ schema.json\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 7. Validate against JSON Schema (optional)\n",
    "When you have a JSON Schema for the canonical MAP import JSON, you can validate the output against it."
   ],
   "id": "49c045626602d32"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T20:07:31.387685Z",
     "start_time": "2025-07-01T20:07:31.381348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Uncomment the code below to use this when you have a JSON Schema\n",
    "\n",
    "# import jsonschema, pathlib, json\n",
    "# schema_doc = json.load(open(\"map_schema_import.schema.json\"))\n",
    "# jsonschema.validate(payload, schema_doc)\n",
    "# print(\"Payload validated against canonical JSON-Schema\")"
   ],
   "id": "40055372526a3e39",
   "outputs": [],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
